{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import *\n",
    "import random\n",
    "import Graph as G\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VecDB():\n",
    "    def __init__(self,R,L,alpha,K,datasetPath='dataset/DB1K.csv'):\n",
    "        self.R=R\n",
    "        self.L=L\n",
    "        self.alpha=alpha\n",
    "        self.k=K\n",
    "        self.datasetPath=datasetPath\n",
    "        self.DBGraph=self.Initialize_Random_Graph()\n",
    "        self.medoid=self.get_medoid()\n",
    "    #TODO: make another constructor\n",
    "        \n",
    "    def load_binary_data(self, binary_file_path):\n",
    "    # Load the data from the binary file\n",
    "        with open(binary_file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        return data\n",
    "    \n",
    "    # Get vertices from DB and insert them into the graph\n",
    "    def Initialize_Random_Graph(self):\n",
    "        DBGraph=G.Graph()\n",
    "        DBdata = self.load_binary_data(self.datasetPath)\n",
    "        for row in DBdata.itertuples(index=True, name='Pandas'):\n",
    "            dataKey = int(row[1])\n",
    "            dataValue= np.array(row[2:],dtype=float)\n",
    "            # print(dataValue)\n",
    "            DBGraph.add_vertex(G.Vertex(dataKey, dataValue))\n",
    "        \n",
    "        size= len(DBGraph.verticies)\n",
    "        if(size==0 or size==1):\n",
    "            return\n",
    "        \n",
    "        #Building Edges\n",
    "        for vertex in DBGraph:\n",
    "            for i in range(self.R):\n",
    "                neighbor= DBGraph.get_vertex(int(random.random()*size))\n",
    "                while(neighbor==vertex):\n",
    "                    neighbor= DBGraph.get_vertex(int(random.random()*size))\n",
    "                DBGraph.add_edge((vertex.key,vertex.value),(neighbor.key,neighbor.value))\n",
    "        return DBGraph\n",
    "\n",
    "\n",
    "    # gets euclidean distance between 2 vectors\n",
    "    def get_distance(self,v1,v2):\n",
    "        return np.dot(v1,v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "        # return  np.linalg.norm(v1-v2)\n",
    "\n",
    "\n",
    "    # # gets medoid of a graph\n",
    "    # def get_medoid(self):\n",
    "    #     min_distance=10000000000000000000\n",
    "    #     medoid=None\n",
    "    #     for vertex in self.DBGraph:\n",
    "    #         current_total_distance=0\n",
    "    #         for vertex2 in self.DBGraph:\n",
    "    #             if(vertex==vertex2):\n",
    "    #                 continue\n",
    "    #             dist=self.get_distance(vertex.value,vertex2.value)\n",
    "    #             current_total_distance+=dist\n",
    "            \n",
    "    #         if(current_total_distance<min_distance):\n",
    "    #             min_distance=current_total_distance\n",
    "    #             medoid=vertex\n",
    "    #     print(medoid.key)\n",
    "    #     return medoid,min_distance\n",
    "    \n",
    "\n",
    "    def get_medoid(self):\n",
    "        vX = list(self.DBGraph.get_vertices())\n",
    "        Embeddings = [self.DBGraph.verticies[i].value for i in vX]\n",
    "        # print(Embeddings)                                            # get all vertices\n",
    "        vMean = np.mean(Embeddings, axis=0)                               # compute centroid\n",
    "        # print(\"vMean\",vMean)\n",
    "        # i = np.argmin([sum((x - vMean)**2) for x in Embeddings])          # pick a point closest to centroid\n",
    "        minIndex = self.DBGraph.get_vertex(np.argmin([sum((x - vMean)**2) for x in Embeddings]))\n",
    "        # print(i)\n",
    "        return minIndex # pick a point closest to centroid\n",
    "\n",
    "\n",
    "\n",
    "    #gets arg min distance from any vertex in Anyset to Query and min dist\n",
    "    def get_min_dist (self,AnyKeysSet,Query):\n",
    "        min_dist=10000000000000000000\n",
    "        min_vertex=None\n",
    "        for vertexKey in AnyKeysSet:\n",
    "            # print(\"vertex\",vertex)\n",
    "            # print(\"Query\",Query[:3])\n",
    "            vertex=self.DBGraph.get_vertex(vertexKey)\n",
    "            dist=self.get_distance(vertex.value,Query)\n",
    "            if(dist<min_dist):\n",
    "                min_dist=dist\n",
    "                min_vertex=vertex\n",
    "        return min_vertex,min_dist\n",
    "    \n",
    "    def get_min_dist_Key (self,AnyKeysSet,Query):\n",
    "        arrKey = list(AnyKeysSet)\n",
    "        arrEmb = [self.DBGraph.get_vertex(i).value for i in arrKey]\n",
    "        arrEmb = np.array(arrEmb) - Query\n",
    "        minDist = np.linalg.norm(arrEmb, axis=1)\n",
    "        minIndex = np.argmin(minDist)\n",
    "        return arrKey[minIndex], minDist[minIndex]\n",
    "\n",
    "        # min_dist=10000000000000000000\n",
    "        # min_vertex=None\n",
    "        # for vertexKey in AnyKeysSet:\n",
    "        #     # print(\"vertex\",vertex)\n",
    "        #     # print(\"Query\",Query[:3])\n",
    "        #     vertex=self.DBGraph.get_vertex(vertexKey)\n",
    "        #     dist=self.get_distance(vertex.value,Query)\n",
    "        #     if(dist<min_dist):\n",
    "        #         min_dist=dist\n",
    "        #         min_vertex=vertex.key\n",
    "        # return min_vertex,min_dist\n",
    "\n",
    "\n",
    "    #initially, start is the medoid\n",
    "    # s is a vertex, Query is a vector\n",
    "    # k is a number, L is a number\n",
    "    # TODO: change them to be indices instead of vertices to save ram\n",
    "    def Greedy_Search(self,start,Query, k):\n",
    "        search_List={start.key}\n",
    "        Visited=set()\n",
    "        #TODO: make the visited and the possible frontier set of indices instead of vertices to save ram.\n",
    "        possible_frontier=search_List\n",
    "        while possible_frontier != set():\n",
    "            # print('possible_frontier',possible_frontier)\n",
    "            p_star,_= self.get_min_dist_Key(possible_frontier,Query)\n",
    "            \n",
    "            # print('pstar',p_star)\n",
    "            # if p_star==None:\n",
    "            #     # break\n",
    "            #     print('frontier: ')\n",
    "            #     for v in possible_frontier:\n",
    "            #         print(v)\n",
    "            #     print(possible_frontier==set())\n",
    "            search_List=search_List.union(self.DBGraph.get_vertex(p_star).neighbors)\n",
    "            Visited.add(p_star)\n",
    "            if(len(search_List)>self.L):\n",
    "                #update search list to retain closes L points to x_q\n",
    "                search_ListL_L=list(search_List)\n",
    "                search_ListL_L.sort(key=lambda x: self.get_distance(self.DBGraph.get_vertex(x).value,Query))\n",
    "                # only maintain L closest points\n",
    "                search_ListL_L=search_ListL_L[:self.L]\n",
    "                search_List=set(search_ListL_L)\n",
    "\n",
    "            possible_frontier=search_List.difference(Visited)\n",
    "            \n",
    "        search_ListL_L=list(search_List)\n",
    "        search_ListL_L.sort(key=lambda x: self.get_distance(self.DBGraph.get_vertex(x).value,Query))\n",
    "        # only maintain k closest points\n",
    "        search_ListL_L=search_ListL_L[:k]\n",
    "        search_List=set(search_ListL_L)\n",
    "        return search_List,Visited\n",
    "\n",
    "    # # Robust pruning \n",
    "    #candidate set is set of integers\n",
    "    def Robust_Prune(self,point,candidate_set,alpha):\n",
    "        # print(candidate_set)\n",
    "        candidate_set=candidate_set.union(point.neighbors)\n",
    "        candidate_set.difference({point.key}) # changed\n",
    "        point.neighbors=set()\n",
    "        # print(\"candidate_set\", candidate_set)\n",
    "        while candidate_set!=set():\n",
    "            # print(\"candidate_set\", candidate_set)\n",
    "            # print(\"point.value\", point.value)\n",
    "            p_star,_= self.get_min_dist_Key(candidate_set,point.value)\n",
    "            point.neighbors.add(p_star)\n",
    "            if(len(point.neighbors)==self.R):\n",
    "                break\n",
    "            DummySet=candidate_set.copy()\n",
    "            for candidatePointKey in candidate_set:\n",
    "                candidatePoint=self.DBGraph.get_vertex(candidatePointKey)\n",
    "                if(alpha * self.get_distance(self.DBGraph.get_vertex(p_star).value,candidatePoint.value)<=self.get_distance(candidatePoint.value,point.value)):\n",
    "                    DummySet.remove(candidatePoint.key)\n",
    "            candidate_set=DummySet\n",
    "\n",
    "\n",
    "    def Build_Index(self):\n",
    "\n",
    "        # R = min(R, len(dataset))\n",
    "\n",
    "        self.iterationOverGraph(1) #alpha=1\n",
    "        self.iterationOverGraph(self.alpha) #alpha=2\n",
    "\n",
    "        \n",
    "        \n",
    "    def iterationOverGraph(self,alpha):\n",
    "        # print('medoid',medoid)\n",
    "        randIndex = list(self.DBGraph.get_vertices())\n",
    "        random.shuffle(randIndex)\n",
    "        # random permutation + sequential graph update\n",
    "        for n in randIndex:\n",
    "            node = self.DBGraph.get_vertex(n)\n",
    "            # print(n)\n",
    "\n",
    "            (_,V) = self.Greedy_Search(self.medoid, node.value, 1)\n",
    "            self.Robust_Prune(node, V, alpha)\n",
    "            neighbors = node.get_neighbors()\n",
    "            \n",
    "            for inbKey in neighbors:\n",
    "                \n",
    "                # CHECK : The backward edge is always added\n",
    "                # check here in case we shouldn't add it in all cases ? Might be incorrect? \n",
    "                inb=self.DBGraph.get_vertex(inbKey)\n",
    "                inb.add_neighbor(node.key)\n",
    "                if len(inb.get_neighbors()) > self.R:\n",
    "                    # print(\"inb.get_neighbors()\", inb.get_neighbors())\n",
    "                    self.Robust_Prune(inb, inb.get_neighbors(), alpha)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_vec=np.random.rand(1,70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "R=5\n",
    "k=10\n",
    "L=15\n",
    "alpha=2\n",
    "path='dataset/DB1k.bin'\n",
    "\n",
    "myDB= VecDB(R,L,alpha,k,path)\n",
    "myDB.Build_Index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vector is:\n",
      "[[0.58593533 0.68738762 0.1723914  0.75323824 0.68048805 0.97076679\n",
      "  0.48625203 0.94239976 0.25571124 0.20423631 0.87498952 0.05386946\n",
      "  0.59576595 0.18948501 0.37569246 0.20307758 0.2373565  0.35118518\n",
      "  0.75945855 0.93627362 0.55356838 0.73425826 0.94921671 0.01132441\n",
      "  0.41297501 0.77622878 0.6010115  0.83107591 0.97026124 0.93494086\n",
      "  0.4413734  0.34635389 0.39783248 0.8236807  0.02345862 0.71017195\n",
      "  0.6005903  0.94973814 0.9625756  0.65009552 0.52344922 0.13525815\n",
      "  0.85015399 0.97255215 0.50463145 0.91154117 0.95979335 0.31388945\n",
      "  0.16201219 0.2123408  0.5877276  0.52483836 0.89089181 0.21673663\n",
      "  0.6916554  0.48581044 0.81342633 0.75301068 0.21536404 0.43615824\n",
      "  0.64233852 0.34350039 0.29961748 0.12036165 0.72786667 0.06520621\n",
      "  0.58445551 0.27294937 0.09631088 0.80516254]]\n",
      "------------------------\n",
      "len of Ler is: 10\n",
      "576\n",
      "4814.606672606314\n",
      "------------------------\n",
      "514\n",
      "4295.877530733715\n",
      "------------------------\n",
      "231\n",
      "1928.1305056699118\n",
      "------------------------\n",
      "616\n",
      "5149.270643078935\n",
      "------------------------\n",
      "361\n",
      "3015.787983951322\n",
      "------------------------\n",
      "619\n",
      "5174.370441073702\n",
      "------------------------\n",
      "434\n",
      "3626.549637261867\n",
      "------------------------\n",
      "403\n",
      "3367.1850921954015\n",
      "------------------------\n",
      "437\n",
      "3651.649432421858\n",
      "------------------------\n",
      "573\n",
      "4789.506875047006\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "Ler,_= myDB.Greedy_Search(myDB.medoid,random_vec, k)\n",
    "\n",
    "actual_query = np.argsort(vectors.dot(query.T).T / (np.linalg.norm(vectors, axis=1) * np.linalg.norm(query)), axis= 1).squeeze().tolist()[::-1]\n",
    "\n",
    "print('The vector is:')\n",
    "print(random_vec)\n",
    "print('------------------------')\n",
    "print('len of Ler is:',len(Ler))\n",
    "for lol in Ler:\n",
    "    print(lol)\n",
    "    print(myDB.get_distance(lol,random_vec))\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_binary(csv_file_path, binary_file_path):\n",
    "    # Read the CSV data\n",
    "    data = pd.read_csv(csv_file_path, header=None)\n",
    "    # print(data)\n",
    "    # Write the data to a binary file\n",
    "    with open(binary_file_path, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "csv_to_binary('dataset/DB1k.csv','dataset/DB1k.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting to Networkx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[2, 3, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OutEdgeView([(0, 1), (1, 0)])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(range(2))\n",
    "# G = nx.path_graph(2)\n",
    "\n",
    "attrs = {0: {\"vec\": [1,2,3,4]}}\n",
    "nx.set_node_attributes(G, attrs)\n",
    "G.nodes[0][\"vec\"]\n",
    "\n",
    "attrs = {1: {\"vec\": [2,3,4]}}\n",
    "nx.set_node_attributes(G, attrs)\n",
    "print(G.nodes())\n",
    "print(G.nodes[1][\"vec\"])\n",
    "\n",
    "G.add_edge(0,1)\n",
    "G.add_edge(1,0)\n",
    "\n",
    "G.edges()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
