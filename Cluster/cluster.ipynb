{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063\n",
      "1032\n",
      "975\n",
      "1055\n",
      "985\n",
      "976\n",
      "1011\n",
      "974\n",
      "1015\n",
      "914\n",
      "ulabels [0 1 2 3 4 5 6 7 8 9]\n",
      "len of ulabels 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# def compute_pca(X, n_components=2):\n",
    "#     \"\"\"\n",
    "#     Input:\n",
    "#         X: of dimension (m,n) where each row corresponds to a word vector\n",
    "#         n_components: Number of components you want to keep.\n",
    "#     Output:\n",
    "#         X_reduced: data transformed in 2 dims/columns + regenerated original data\n",
    "#     \"\"\"\n",
    "#     X_reduced = None\n",
    "#     ####################### TODO: Use sklearn.decomposition.PCA to implement this function #####################\n",
    "#     X_reduced = PCA(n_components=n_components).fit_transform(X)\n",
    "#     ###########################################################################################################\n",
    "#     return X_reduced\n",
    "\n",
    "# DB_Path=\"dataset/\"\n",
    "# DB=None\n",
    "# with open(DB_Path+'DB1k.csv', 'r', newline='') as f:\n",
    "#     DB = f.readlines()\n",
    "#     DB = [x.strip() for x in DB]\n",
    "#     for i,x in enumerate(DB):\n",
    "#             x=x.split(',')\n",
    "#             x=np.array(x[1:],dtype=np.float32)\n",
    "#             DB[i]=x   \n",
    "    #  print(len(DB))\n",
    "    # print(DB)\n",
    "DB_SEED_NUMBER=50\n",
    "rng = np.random.default_rng(DB_SEED_NUMBER)\n",
    "DB = rng.random((10**4, 70), dtype=np.float32)\n",
    "# result = compute_pca(DB, 2)\n",
    "# plt.scatter(result[:, 0], result[:, 1])\n",
    "# plt.show()\n",
    "# print(result.shape)\n",
    "# result=result.reshape(1,-1)\n",
    "# length = np.sqrt((result**2).sum(axis=1))[:,None]\n",
    "# result = result / length\n",
    "# db = DBSCAN(eps=epsilon, min_samples=10,metric=\"cosine\").fit(result)\n",
    "# db = KMeans(n_clusters=10).fit(result)\n",
    "# good eps 0.005 and min_samples = 10 for DBSCAN 10k ==> N_cluster=32\n",
    "# for 100k ==> N_cluster=11 for epsilon=0.00068 and min_samples=10\n",
    "# for 1M ==> N_cluster=11 for epsilon=0.000068 and min_samples=10\n",
    "# for 1M ==> N_cluster=10 for epsilon=0.00008 and min_samples=10\n",
    "# for 1M ==> N_cluster=503 for epsilon=0.00006 and mixn_samples=10\n",
    "# for 1M ==> N_cluster=131 for epsilon=0.000067 and mixn_samples=10\n",
    "# epsilon=0.000067\n",
    "# epsilon=10**-25\n",
    "# db = DBSCAN(eps=epsilon, min_samples=10,metric='cosine').fit(DB)\n",
    "# print(db.labels_)\n",
    "db=KMeans(n_clusters=10).fit(DB)\n",
    "#divide db accoding to which label it was classsified\n",
    "for label in np.unique(db.labels_):\n",
    "    indices = np.where(db.labels_ == label)\n",
    "    temp =DB[indices]\n",
    "    print(len(temp))\n",
    "# print(np.count_nonzero(db.labels_ ==5))\n",
    "print('ulabels',np.unique(db.labels_))\n",
    "print('len of ulabels',len(np.unique(db.labels_)))\n",
    "# plt.scatter(result[:, 0], result[:, 1], c=db.labels_)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ulabels [ -1   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16\n",
      "  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34\n",
      "  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52\n",
      "  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70\n",
      "  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88\n",
      "  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106\n",
      " 107 108 109 110 111]\n",
      "len of ulabels 113\n"
     ]
    }
   ],
   "source": [
    "# print(db.labels_)\n",
    "# print(np.unique(db.labels_))\n",
    "epsilon=0.000068\n",
    "db = DBSCAN(eps=epsilon, min_samples=10).fit(result)\n",
    "# print(db.labels_)\n",
    "print('ulabels',np.unique(db.labels_))\n",
    "print('len of ulabels',len(np.unique(db.labels_)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
